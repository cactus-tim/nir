{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pip install torch>=2.1.0 transformers>=4.34.0 peft>=0.5.0 accelerate>=0.20.0"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%pip install huggingface_hub"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ef0576b8911a75d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3b9c2724f8e0e1a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import get_peft_model, PrefixTuningConfig, TaskType\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ec109c13c602e2c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ChatDataset(Dataset):\n",
    "    def __init__(self, tokenizer, data_path, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = []\n",
    "        self.max_length = max_length\n",
    "\n",
    "        with open(data_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                ex = json.loads(line)\n",
    "                prompt = ex['input_text'].strip()\n",
    "                completion = ex['output_text'].strip()\n",
    "                text = prompt + completion\n",
    "                self.data.append(text)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data[idx]\n",
    "        tokens = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': tokens.input_ids.squeeze(0),\n",
    "            'attention_mask': tokens.attention_mask.squeeze(0),\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "871d972592e1d10f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [b['input_ids'] for b in batch]\n",
    "    attention_mask = [b['attention_mask'] for b in batch]\n",
    "\n",
    "    input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "        input_ids, batch_first=True, padding_value=tokenizer.pad_token_id\n",
    "    )\n",
    "    attention_mask = torch.nn.utils.rnn.pad_sequence(\n",
    "        attention_mask, batch_first=True, padding_value=0\n",
    "    )\n",
    "\n",
    "    labels = input_ids.clone()\n",
    "    return {'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51d9d446e39ad8bc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MODEL_NAME = \"mistralai/Mistral-7B-v0.1\"\n",
    "DATA_PATH = \"./prefix_tuning_dataset.jsonl\"\n",
    "OUTPUT_DIR = \"./mistral_prefix_tuned\"\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 3\n",
    "LR = 2e-5\n",
    "NUM_VIRTUAL_TOKENS = 50\n",
    "MAX_LENGTH = 256"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "500611bc10b1dcbd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "peft_config = PrefixTuningConfig(\n",
    "    peft_type=\"PREFIX_TUNING\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    num_virtual_tokens=50,\n",
    "    encoder_hidden_size=model.config.hidden_size\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d095882ea710b234"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = ChatDataset(tokenizer, DATA_PATH, max_length=MAX_LENGTH)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d7f6fd17712b70a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        for k in batch:\n",
    "            batch[k] = batch[k].to(model.device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(**batch)\n",
    "        loss = out.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if step % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1} Step {step} — loss {loss.item():.4f}\")\n",
    "\n",
    "    avg = total_loss / len(train_loader)\n",
    "    print(f\"=== Epoch {epoch+1} done — avg loss {avg:.4f} ===\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9648b67cba9faaba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ee9dda409713605"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
